{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.programcreek.com/python/example/100588/keras.layers.normalization.BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.initializers import lecun_uniform\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def construct_model(layers=[50,50], activation='relu', a_reg='l1', b_reg='l1', b_init='random_uniform', k_init='random_uniform', dropout=.0,\\\n",
    "                    a_dropout=.0, optimizer='sgd', loss='binary_crossentropy', metrics='roc_auc_score',input_dim=17, output_dim=1, model_name='most'):\n",
    "    \"\"\"\n",
    "    Helper to construct a Keras model based on dict of specs and input size\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_spec: dict\n",
    "        Dict containing keys: arch, activation, dropout, optimizer, loss,\n",
    "            w_reg, metrics\n",
    "    input_dim: int\n",
    "        Size of input dimension\n",
    "    output_dim: int\n",
    "        Size of input dimension\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model: Compiled keras.models.Sequential\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    for li, layer_size in enumerate(layers):\n",
    "        # For input layer, add input dimension\n",
    "        if li == 0:\n",
    "            temp_input_dim = input_dim\n",
    "            model.add(Dense(layer_size,\n",
    "                            input_dim=input_dim,\n",
    "                            activation=activation,\n",
    "                            activity_regulizer=model_spec['a-reg'],\n",
    "                            bias_regulizer=model_sepc['b-reg'],\n",
    "                            bias_initializer=model_spec['b-init'],\n",
    "                            kernel_initializer=model_spec['k-init'],\n",
    "                            name='Input'))\n",
    "        elif li < len(layers)-1:\n",
    "            model.add(Dense(layer_size,\n",
    "                            activation=model_spec['activation'],\n",
    "                            activity_regulizer=model_spec['a-reg'],\n",
    "                            bias_regulizer=model_spec['b-reg'],\n",
    "                            bias_initializer=model_spec['b-init'],\n",
    "                            kernel_initializer=model_spec['k-init'],\n",
    "                            name='Layer_%i' % li))\n",
    "        elif li == len(layers)-1:\n",
    "            model.add(Dense( output_dim ,\n",
    "                            activation='sigmoid',\n",
    "                            activity_regulizer=model_spec['a-reg'],\n",
    "                            bias_regulizer=model_spec['b-reg'],\n",
    "                            bias_initializer=model_spec['b-init'],\n",
    "                            kernel_initializer=model_spec['k-init'],\n",
    "                            name='Layer_%i' % li))\n",
    "            \n",
    "        if model_spec['dropout'] > 0.:\n",
    "            model.add(Dropout(model_spec['dropout'], name='Dropout_%i' % li))\n",
    "        if model_spec['a-dropout'] > 0.:\n",
    "            model.add(Dropout(model_spec['a-dropout'], name='Dropout_%i' % li))\n",
    "    model.compile(optimizer=model_spec['optimizer'],\n",
    "                  loss=model_spec['loss'],\n",
    "                  metrics=model_spec['metrics'])\n",
    "    return model \n",
    "model = KerasClassifier(build_fn=construct_model, epochs=100, batch_size=32,\\\n",
    "                       verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snir\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Snir\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#custom scoring function sklearn\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def lift_index(y, probabilities):\n",
    "    #rearrange probabilities and y in descending order\n",
    "    combine = zip(y, probabilities)\n",
    "    dtype = [('data', int), ('prob', float)]\n",
    "    combine = np.array(combine,dtype=dtype)\n",
    "    combine = np.sort(combine, order='prob')\n",
    "    ordered = np.sort(probabilities)\n",
    "    #divide into deciles\n",
    "    deciles = pd.qcut(ordered, 10)\n",
    "    #amount of positive in each decile\n",
    "    i=0\n",
    "    sum_deciles = sum([sum([((num/10)+0.1)*combine[i][0] for i in deciles if i==num ]) for num in range(10)])\n",
    "    return sum_deciles/sum(y)\n",
    "lift_index_score = make_scorer(lift_index, greater_is_better=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title='Normalized confusion matrix'\n",
    "    else:\n",
    "        title='Confusion matrix'\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "#fix seed for reproducibility\n",
    "seed=7\n",
    "np.random.seed(seed)\n",
    "#import data without any dummy variables or changes\n",
    "param_grid = {'dense_layers': [[100,100],[100,100,100],[50,50,50,50]],\n",
    "              'activation':['relu','selu'],\n",
    "              'dropout': [0.0, 0.5],\n",
    "              'a-dropout': [0.0,0.2],\n",
    "              'k-init': ['lecun_normal'],\n",
    "              'b-init': ['lecun_normal'],\n",
    "              'a-reg': ['l1'],\n",
    "              'b-reg': ['l2'],\n",
    "              'optimizer':('rmsprop','adam'),\n",
    "              'epochs':[10,50,100],\n",
    "              'batch_size':[128,32,16]}\n",
    "#improve with article\n",
    "grid = GridSearchCV(model,\n",
    "                    param_grid=param_grid,\n",
    "                    return_train_score=True,\n",
    "                    scoring=[lift_index_score,'roc_auc_score'],\n",
    "                    refit='roc_auc_score',\n",
    "                    n_jobs=-1)\n",
    "\n",
    "#grid_results = grid.fit(x_train,y_train)\n",
    "#means = grid_result.cv_results_['mean_test_score']\n",
    "#stds = grid_result.cv_results_['std_test_score']\n",
    "#params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "#    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualization\n",
    "from keras.utils import plot_model\n",
    "#visualize best model\n",
    "# use params from prev cell to visualize\n",
    "#visualize\n",
    "plot_model(model, to_file='model_%.png' % model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
