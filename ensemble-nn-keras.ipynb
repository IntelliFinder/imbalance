{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.programcreek.com/python/example/100588/keras.layers.normalization.BatchNormalization\n",
    "import keras \n",
    "import sklearn\n",
    "keras.initializers.lecun_uniform(seed=None)\n",
    "keras.layers.GaussianNoise(stddev)\n",
    "keras.activations.selu(x)\n",
    "keras.layers.AlphaDropout(rate, noise_shape=keras.layers None, seed=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.initializers import lecun_uniform\n",
    "\n",
    "\n",
    "def construct_model(layers=[50,50], activation='relu', a_reg='l1', b_reg='l1', b_init='random_uniform', k_init='random_uniform', dropout=.0\\\n",
    "                    a_dropout=.0, optimizer='sgd', loss='binary_crossentropy', metrics='roc_auc_score',input_dim=17, output_dim=1, model_name='most'):\n",
    "    \"\"\"\n",
    "    Helper to construct a Keras model based on dict of specs and input size\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_spec: dict\n",
    "        Dict containing keys: arch, activation, dropout, optimizer, loss,\n",
    "            w_reg, metrics\n",
    "    input_dim: int\n",
    "        Size of input dimension\n",
    "    output_dim: int\n",
    "        Size of input dimension\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model: Compiled keras.models.Sequential\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    for li, layer_size in enumerate(layers):\n",
    "        # Set output size for last layer\n",
    "        if layer_size == 'None':\n",
    "            layer_size = output_dim\n",
    "\n",
    "        # For input layer, add input dimension\n",
    "        if li == 0:\n",
    "            temp_input_dim = input_dim\n",
    "            model.add(Dense(layer_size,\n",
    "                            input_dim=input_dim,\n",
    "                            activation=model_spec['activation'],\n",
    "                            activity_regulizer=model_spec['a-reg'],\n",
    "                            bias_regulizer=model_sepc['b-reg'],\n",
    "                            bias_initializer=model_spec['b-init'],\n",
    "                            kernel_initializer=model_spec['k-init'],\n",
    "                            name='Input'))\n",
    "        else:\n",
    "            model.add(Dense(layer_size,\n",
    "                            activation=model_spec['activation'],\n",
    "                            activity_regulizer=model_spec['a-reg'],\n",
    "                            bias_regulizer=model_spec['b-reg'],\n",
    "                            bias_initializer=model_spec['b-init'],\n",
    "                            kernel_initializer=model_spec['k-init'],\n",
    "                            name='Layer_%i' % li))\n",
    "\n",
    "        if model_spec['dropout'] > 0.:\n",
    "            model.add(Dropout(model_spec['dropout'], name='Dropout_%i' % li))\n",
    "        if model_spec['a-dropout'] > 0.:\n",
    "            model.add(Dropout(model_spec['a-dropout'], name='Dropout_%i' % li))\n",
    "    model.compile(optimizer=model_spec['optimizer'],\n",
    "                  loss=model_spec['loss'],\n",
    "                  metrics=model_spec['metrics'])\n",
    "    return model \n",
    "model = KerasClassifier(build_fn=construct_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#custom scoring function sklearn\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def lift_index(y, probabilities):\n",
    "    #rearrange probabilities and y in descending order\n",
    "    combine = zip(y, probabilities)\n",
    "    dtype = [('data', int), ('prob', float)]\n",
    "    combine = np.array(combine,dtype=dtype)\n",
    "    combine = np.sort(combine, order='prob')\n",
    "    ordered = np.sort(probabilities)\n",
    "    #divide into deciles\n",
    "    deciles = pd.qcut(ordered, 10)\n",
    "    #amount of positive in each decile\n",
    "    i=0\n",
    "    sum_deciles = sum([sum([((num/10)+0.1)combine[i][0] for i in deciles if i==num ]) for num in range(10)])\n",
    "    return sum_deciles/sum(y)\n",
    "lift_index_score = make_scorer(lift_index, greater_is_better=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title='Normalized confusion matrix'\n",
    "    else:\n",
    "        title='Confusion matrix'\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "#grid search\n",
    "#import data without any dummy variables or changes\n",
    "param_grid = {'dense_layers': [[100,100],[100,100,100],[50,50,50,50]],\n",
    "              'activation':['relu','selu'],\n",
    "              'optimizer':('rmsprop','adam'),\n",
    "              'epochs':[10,50,100],\n",
    "              'batch_size':[128,32,16]}\n",
    "#improve with article\n",
    "grid = GridSearchCV(model,\n",
    "                    param_grid=param_grid,\n",
    "                    return_train_score=True,\n",
    "                    scoring=[lift_index_score,'roc_auc_score'],\n",
    "                    refit='roc_auc_score')\n",
    "\n",
    "grid_results = grid.fit(x_train,y_train)\n",
    "\n",
    "print('Parameters of the best model: ')\n",
    "print(grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualization\n",
    "from keras.utils import plot_model\n",
    "#call helper function with dataframe with all possible combinations\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "#analyse model\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)\n",
    "#visualize\n",
    "plot_model(model, to_file='model_%.png' % model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
